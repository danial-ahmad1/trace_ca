{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# May not need all of these\n",
    "\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "from ipywidgets import interact, widgets\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from aicsimageio import AICSImage\n",
    "from scipy.signal import find_peaks\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.ndimage import binary_dilation\n",
    "from scipy.signal import butter, filtfilt\n",
    "from tqdm import tqdm\n",
    "from skimage import io, filters, morphology\n",
    "from skimage.util import img_as_ubyte, img_as_float, img_as_uint\n",
    "from skimage.filters import rank\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.morphology import disk\n",
    "from skimage.io import imsave\n",
    "import cv2\n",
    "from skimage import measure, feature, color\n",
    "from skimage.draw import disk\n",
    "from skimage.feature import blob_dog, blob_log, blob_doh\n",
    "import heapq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of files for Dan to test\n",
    "# '/Users/moose/Downloads/1.2 OD TraCE 1 01112024/WT 1.2OD 0.5 um_1_2024-01-11_Confocal_01.00.49_DragonflyUser.ims'\n",
    "# '/Users/moose/Downloads/1.2 OD TraCE 1 01112024/WT 1.2OD 0.5 um_2_2024-01-11_Confocal_01.16.28_DragonflyUser.ims'\n",
    "# '/Users/moose/Downloads/1.2 OD TraCE 1 01112024/WT 1.2OD 0.5 um_3_2024-01-11_Confocal_01.08.43_DragonflyUser.ims'\n",
    "\n",
    "# '/Users/moose/Downloads/1.2 OD TraCE 1 01112024/PBP4 1.2OD 0.5 um_1_2024-01-11_Confocal_01.23.49_DragonflyUser.ims'\n",
    "# '/Users/moose/Downloads/1.2 OD TraCE 1 01112024/PBP4 1.2OD 0.5 um_2_2024-01-11_Confocal_01.30.50_DragonflyUser.ims'\n",
    "# '/Users/moose/Downloads/1.2 OD TraCE 1 01112024/PBP4 1.2OD 0.5 um_3_2024-01-11_Confocal_01.40.34_DragonflyUser.ims'\n",
    "\n",
    "# '/Users/moose/Downloads/1.2 OD TraCE 1 01112024/WT 1.2OD Nonporous_2024-01-10_Confocal_22.39.44_DragonflyUser.ims'\n",
    "\n",
    "# '/Users/moose/Downloads/Controls 20240418/WT DNase_2024-04-18_Confocal_00.55.19_DragonflyUser.ims'\n",
    "\n",
    "# '/Users/moose/Downloads/Controls 20240418/WT 1 window_2024-04-18_Confocal_00.33.17_DragonflyUser_FusionStitcher.ims' Do not use!\n",
    "\n",
    "# '/Users/moose/Downloads/Controls 20240418/WT 1 stack_2024-04-18_Confocal_00.48.57_DragonflyUser.ims' Good test stack for budding events, slightly tilted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can take raw .ims files\n",
    "\n",
    "file_name = '/Users/moose/Downloads/1.2 OD TraCE 1 01112024/WT 1.2OD Nonporous_2024-01-10_Confocal_22.39.44_DragonflyUser.ims'\n",
    "image = AICSImage(file_name)\n",
    "image_data = image.get_image_data(\"ZYX\", S=0, T=0, C=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global variables\n",
    "key_frame = '/Users/moose/Desktop/trace_ca-local/key-frame-ca.tif'\n",
    "key_img = io.imread(key_frame)\n",
    "\n",
    "# Some of these are not used, remove later\n",
    "DoG_thresh = 0.3\n",
    "lowerbound = 2\n",
    "search_mod = 25\n",
    "z_project = 10\n",
    "\n",
    "BlurToggle = False\n",
    "gkernal = (21, 21)\n",
    "\n",
    "DilateToggle = False\n",
    "dstructure = np.ones((3, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All relevant functions\n",
    "\n",
    "def subtractflatfield(input_img):\n",
    "    grayscale_img = input_img\n",
    "    poly2d_fcn = lambda xy, a, b, c, d, e, f: a + b*xy[0] + c*xy[1] + d*xy[0]*xy[0] + e*xy[1]*xy[1] + f*xy[0]*xy[1]\n",
    "\n",
    "    y, x = np.indices(grayscale_img.shape)\n",
    "\n",
    "    x_co = x.flatten()\n",
    "    y_co = y.flatten()\n",
    "    pix_val = grayscale_img.flatten()\n",
    "\n",
    "    p0 = [1, 1, 1, 1, 1, 1]\n",
    "    popt, _ = curve_fit(poly2d_fcn, (x_co, y_co), pix_val, p0=p0) \n",
    "    flat_field_img = poly2d_fcn((x_co, y_co), *popt).reshape(grayscale_img.shape)\n",
    "    fit_img = grayscale_img - (flat_field_img)\n",
    "\n",
    "    return fit_img\n",
    "\n",
    "def means_match(input_img, kfimg):\n",
    "        # kfmod = subtractflatfield(kfimg)\n",
    "        kfmean = np.mean(kfimg)\n",
    "\n",
    "        # xmod_loss = []\n",
    "\n",
    "        best_mean_diff = np.inf\n",
    "        best_xmod = 0\n",
    "        mean_diff = 0\n",
    "        bftest = input_img\n",
    "        bfmin = np.min(bftest)\n",
    "            \n",
    "        for xmod in tqdm(np.linspace(0.1, 10, 200), desc='Means Matching'):\n",
    "            xmodtest = np.clip(xmod * (bftest - bfmin), np.min(kfimg), np.max(kfimg))\n",
    "            mean_xmodtest = np.mean(xmodtest)\n",
    "            mean_diff = abs(mean_xmodtest - kfmean)\n",
    "\n",
    "            # xmod_loss = mean_diff # Diagnostic\n",
    "                \n",
    "            if mean_diff < best_mean_diff:\n",
    "                best_mean_diff = mean_diff\n",
    "                best_xmod = xmod\n",
    "\n",
    "            if mean_diff < 0.0005:\n",
    "                print(f'Image is at an acceptable target, stopping iterations')\n",
    "                break\n",
    "\n",
    "            bfimg = np.clip(best_xmod * (input_img - np.min(input_img)), np.min(kfimg), np.max(kfimg))\n",
    "\n",
    "        return bfimg, best_xmod\n",
    "\n",
    "def background_subtract(img_dat):\n",
    "    x1 = np.min(img_dat)\n",
    "    x2 = []\n",
    "    for i in range(len(img_dat)):\n",
    "        x2.append(img_dat[i] - x1)\n",
    "\n",
    "    x2 = np.maximum(x2, 0)\n",
    "\n",
    "    return x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Z-stack processing\n",
    "\n",
    "frame_mean = []\n",
    "frame_min = []\n",
    "frame_max = []\n",
    "frame_std = []\n",
    "frame_95 = []\n",
    "frame_05 = []\n",
    "for i in range(len(image_data)):\n",
    "    frame_mean.append(np.mean(image_data[i]))\n",
    "    frame_min.append(np.min(image_data[i]))\n",
    "    frame_max.append(np.max(image_data[i]))\n",
    "    frame_std.append(np.std(image_data[i]))\n",
    "    frame_95.append(np.percentile(image_data[i], 95))\n",
    "    frame_05.append(np.percentile(image_data[i], 5))\n",
    "\n",
    "plusband = []\n",
    "minusband = []\n",
    "for i in range(len(image_data)):\n",
    "    plusband.append(frame_mean[i] + frame_std[i])\n",
    "    minusband.append(frame_mean[i] - frame_std[i])\n",
    "\n",
    "frame_mean_top = []\n",
    "frame_mean_bottom = []\n",
    "for i in range(len(image_data)//2):\n",
    "    frame_mean_bottom.append(frame_mean[i])\n",
    "\n",
    "for i in range(len(image_data)//2, len(image_data)):\n",
    "    frame_mean_top.append(frame_mean[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find highest peak, currently needs logic for multiple peaks\n",
    "\n",
    "background_collect = background_subtract(frame_mean)\n",
    "peaks2, _ = find_peaks(background_collect, height = 1)\n",
    "print(peaks2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensemble model for finding membrane layer z-stack via focus measures\n",
    "\n",
    "hist_key = {}\n",
    "\n",
    "for i in range(peaks2[0]-search_mod, peaks2[0]):\n",
    "    if i > 0:\n",
    "        hist_key[i] = image_data[i]\n",
    "\n",
    "for i in range(peaks2[0], peaks2[0]+search_mod+1):\n",
    "    if i < len(image_data):\n",
    "        hist_key[i] = image_data[i]\n",
    "\n",
    "hist_stdev = {}\n",
    "for i in hist_key.keys():\n",
    "    hist_stdev[i] = np.std(hist_key[i])\n",
    "\n",
    "hist_laplace = {}\n",
    "hist_laplace_focusemeasure = {}\n",
    "for i in hist_key.keys():\n",
    "    hist_laplace[i] = cv2.Laplacian(hist_key[i], cv2.CV_64F)\n",
    "    hist_laplace_focusemeasure[i] = np.var(hist_laplace[i])\n",
    "\n",
    "hist_tenengrad_focusemeasure = {}\n",
    "hist_squared_grad = {}\n",
    "for i in hist_key.keys():\n",
    "    sobelx = cv2.Sobel(hist_key[i], cv2.CV_64F, 1, 0, ksize=5)\n",
    "    sobely = cv2.Sobel(hist_key[i], cv2.CV_64F, 0, 1, ksize=5)\n",
    "\n",
    "    magnitude = np.sqrt(sobelx**2 + sobely**2)\n",
    "    squared_grad = (sobelx**2 + sobely**2)\n",
    "\n",
    "    hist_tenengrad_focusemeasure[i] = np.var(magnitude)\n",
    "    hist_squared_grad[i] = np.var(squared_grad)\n",
    "\n",
    "\n",
    "hist_brenner_focusemeasure = {}\n",
    "for i in hist_key.keys():\n",
    "    shifted_right = np.roll(hist_key[i], -1, axis=1)\n",
    "    shifted_down = np.roll(hist_key[i], -1, axis=0)\n",
    "\n",
    "    diff_right = (shifted_right - hist_key[i])[:-1, :-1] ** 2\n",
    "    diff_down = (shifted_down - hist_key[i])[:-1, :-1] ** 2\n",
    "\n",
    "    sum_diff = np.sum(diff_right) + np.sum(diff_down)\n",
    "    hist_brenner_focusemeasure[i] = sum_diff\n",
    "\n",
    "hist_max = {}\n",
    "for i in hist_key.keys():\n",
    "    hist_max[i] = np.max(hist_key[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Max Stdev: ' + str(np.max(list(hist_stdev.values()))) + ' at Frame ' + str(max(hist_stdev, key=hist_stdev.get)))\n",
    "print(f'Max Laplace: ' + str(np.max(list(hist_laplace_focusemeasure.values())))+ ' at Frame ' + str(max(hist_laplace_focusemeasure, key=hist_laplace_focusemeasure.get)))\n",
    "print(f'Max Tenengrad: ' + str(np.max(list(hist_tenengrad_focusemeasure.values())))+ ' at Frame ' + str(max(hist_tenengrad_focusemeasure, key=hist_tenengrad_focusemeasure.get)))\n",
    "print(f'Max Squared Grad: ' + str(np.max(list(hist_squared_grad.values())))+ ' at Frame ' + str(max(hist_squared_grad, key=hist_squared_grad.get)))\n",
    "print(f'Max Brenner: ' + str(np.max(list(hist_brenner_focusemeasure.values())))+ ' at Frame ' + str(max(hist_brenner_focusemeasure, key=hist_brenner_focusemeasure.get)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finalize vote\n",
    "\n",
    "weight_mat = [1, 1, 1, 1, 1, 1]\n",
    "focus_margins = []\n",
    "\n",
    "# stdev_two_largest = heapq.nlargest(2, hist_stdev.values())\n",
    "# laplace_two_largest = heapq.nlargest(2, hist_laplace_focusemeasure.values())\n",
    "# tenengrad_two_largest = heapq.nlargest(2, hist_tenengrad_focusemeasure.values())\n",
    "\n",
    "stdev_stdev = np.std(list(hist_stdev.values()))\n",
    "laplace_stdev = np.std(list(hist_laplace_focusemeasure.values()))\n",
    "tenengrad_stdev = np.std(list(hist_tenengrad_focusemeasure.values()))\n",
    "squared_grad_stdev = np.std(list(hist_squared_grad.values()))\n",
    "brenner_stdev = np.std(list(hist_brenner_focusemeasure.values()))\n",
    "\n",
    "\n",
    "weight_mat[0] = stdev_stdev/np.mean(list(hist_stdev.values()))\n",
    "weight_mat[1] = laplace_stdev/np.mean(list(hist_laplace_focusemeasure.values()))\n",
    "weight_mat[2] = tenengrad_stdev/np.mean(list(hist_tenengrad_focusemeasure.values()))\n",
    "weight_mat[3] = squared_grad_stdev/np.mean(list(hist_squared_grad.values()))\n",
    "weight_mat[4] = brenner_stdev/np.mean(list(hist_brenner_focusemeasure.values()))\n",
    "\n",
    "focus_ensemble = []\n",
    "focus_ensemble.append(max(hist_stdev, key=hist_stdev.get))\n",
    "focus_ensemble.append(max(hist_laplace_focusemeasure, key=hist_laplace_focusemeasure.get))\n",
    "focus_ensemble.append(max(hist_tenengrad_focusemeasure, key=hist_tenengrad_focusemeasure.get))\n",
    "focus_ensemble.append(max(hist_squared_grad, key=hist_squared_grad.get))\n",
    "focus_ensemble.append(max(hist_brenner_focusemeasure, key=hist_brenner_focusemeasure.get))\n",
    "\n",
    "voting_power = []\n",
    "for i in range(len(focus_ensemble)):\n",
    "    voting_power.append((focus_ensemble[i], weight_mat[i]))\n",
    "\n",
    "vote = {}\n",
    "for frame_num, weighted_vote in voting_power:\n",
    "    if frame_num in vote:\n",
    "        vote[frame_num] += weighted_vote\n",
    "\n",
    "    else:\n",
    "        vote[frame_num] = weighted_vote\n",
    "\n",
    "print(f'Final Vote - Membrane Layer at:  ' + str(max(vote, key=vote.get)))\n",
    "mem_layer = max(vote, key=vote.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start constructing z-projection for detecting budding events below the membrane surface. Uses z-project variable as number of layers used (note each layer is roughly 1Âµm)\n",
    "\n",
    "bud_test = []\n",
    "for i in range(z_project):\n",
    "    bud_test.append(mem_layer-i-1)\n",
    "\n",
    "bud_test_img = []\n",
    "for i in bud_test:\n",
    "    bud_test_img.append(hist_key[i])\n",
    "\n",
    "bud_composite = np.max(bud_test_img, axis=0)\n",
    "\n",
    "bud_img = bud_composite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Means match the bud image to the key image, uses 16-bit images for logic. \n",
    "matched_im, xtest = means_match(bud_img, key_img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then subtract backfield.\n",
    "submatched_im = subtractflatfield(matched_im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert down to grayscale 8-bit for processing\n",
    "norm_flat = (submatched_im - np.min(submatched_im)) / (np.max(submatched_im) - np.min(submatched_im))\n",
    "np.clip(norm_flat, 0, 1, out=norm_flat)\n",
    "norm_flat = img_as_ubyte(norm_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Threshold image\n",
    "norm_thresh = np.percentile(norm_flat, 99)\n",
    "norm_brightest = np.where(norm_flat > norm_thresh, 255, 0)\n",
    "\n",
    "# plt.figure(dpi=300)\n",
    "# plt.imshow(norm_brightest, cmap='gray')\n",
    "# plt.axis('off')\n",
    "# # plt.savefig('/Users/moose/Desktop/trace_ca-local/' + os.path.splitext(os.path.basename(file_name))[0] + '_binary.tif', dpi=500)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Morphological analysis\n",
    "closed_im = morphology.closing(norm_brightest, morphology.square(1))\n",
    "label_im = measure.label(closed_im)\n",
    "region_im = measure.regionprops(label_im, intensity_image=norm_flat)\n",
    "# for part in region_im:\n",
    "#     print('Label: {} Area: {}'.format(part.label, part.area))\n",
    "\n",
    "area_list = []\n",
    "for part in region_im:\n",
    "    area_list.append(part.area)\n",
    "\n",
    "delete_small_components = filters.threshold_otsu(np.array(area_list)) \n",
    "area_list = [part for part in area_list if delete_small_components < part < 10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intensity_list = []\n",
    "for part in region_im:\n",
    "    intensity_list.append(part.mean_intensity)\n",
    "\n",
    "int_cut = np.percentile(intensity_list, 50)\n",
    "intensity_list = [part for part in intensity_list if  int_cut < part]\n",
    "\n",
    "eccentricity_list = []\n",
    "for part in region_im:\n",
    "    eccentricity_list.append(part.eccentricity)\n",
    "\n",
    "eccentricity_list = [part for part in eccentricity_list if 0.05 < part < 0.99]\n",
    "\n",
    "area_list_thresh = np.percentile(area_list, 95)\n",
    "mean_comp = np.percentile(intensity_list, 95)\n",
    "lower_ecc = np.percentile(eccentricity_list, 5)\n",
    "higher_ecc = np.percentile(eccentricity_list, 95)\n",
    "\n",
    "filter_area_low = area_list_thresh \n",
    "filter_eccentricity_low = lower_ecc\n",
    "filter_eccentricity_high = higher_ecc\n",
    "region_im_filtered = [part for part in region_im if filter_area_low < part.area < 10000]\n",
    "region_im_filtered = [part for part in region_im if filter_eccentricity_low < part.eccentricity < filter_eccentricity_high]\n",
    "region_im_filtered = [part for part in region_im_filtered if part.mean_intensity > mean_comp]\n",
    "\n",
    "print('Raw Regions: {}'.format(len(region_im)))\n",
    "print('Filtered Regions: {}'.format(len(region_im_filtered)))\n",
    "for part in region_im_filtered:\n",
    "    print('Centroid: ({:.0f}, {:.0f}) | Area: {} | Eccentricity {:.2f} | Mean Intensity {:.2f}'.format(part.centroid[0], part.centroid[1], part.area, part.eccentricity, part.mean_intensity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_alt, ax_alt = plt.subplots(dpi=300)\n",
    "ax_alt.imshow(norm_flat, cmap='gray')\n",
    "for region in region_im_filtered:\n",
    "    y, x = region.centroid\n",
    "    radius = np.sqrt(region.area / np.pi)\n",
    "\n",
    "    circle = plt.Circle((x, y), np.where(radius*5 < 15, radius*5, 15), fill=False, edgecolor='red')\n",
    "    ax_alt.add_patch(circle)\n",
    "   \n",
    "ax_alt.invert_yaxis()\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(10, 5))\n",
    "\n",
    "axs[0].imshow(matched_im, cmap = 'gray')\n",
    "axs[0].set_title('Matched Image')\n",
    "\n",
    "axs[1].imshow(key_img, cmap = 'gray')\n",
    "axs[1].set_title('Key Figure')\n",
    "\n",
    "axs[2].imshow(norm_flat, cmap = 'gray')\n",
    "axs[2].set_title('Subtracted Image')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,5), dpi=150)\n",
    "plt.hist(matched_im.ravel(), bins = 100, range = ((0, 1200)), alpha = 0.5, label = 'Matched Image')\n",
    "plt.hist(key_img.ravel(), bins = 100, range = ((0, 1200)), alpha = 0.5, label = 'Key Image')\n",
    "\n",
    "plt.title('Stack Statistics')\n",
    "plt.xlabel('Bin')\n",
    "plt.ylabel('Histogram Value')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
